{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "38f-9AkHb6Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import re\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2e8oEf-cJGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# #replace with the location of your Part4 folder...\n",
        "# %cd \"/content/drive/My Drive/Colab Notebooks\"\n",
        "# !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqcYnz0Bb6Bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model, Input, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import xception\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD, Adam,Adagrad\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from math import sqrt\n",
        "from keras.callbacks import History \n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import Activation\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import xception\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, merge, concatenate\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense,Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.activations import relu\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.callbacks import History"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ6yvWhBb6CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get all the array values from the npy files \n",
        "train_img = np.load('train_images.npy')\n",
        "train_mask = np.load('train_masks.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUoHePlub6CI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########need to resize the images to pass it to U-net \n",
        "import random\n",
        "# indices = np.random.choice(range(len(train_img)), replace = False ,size = 100)\n",
        "\n",
        "X = train_img[:, :,:,np.newaxis]/255\n",
        "y= train_mask[:,:,:,np.newaxis]/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EroGBMlKb6CQ",
        "colab_type": "code",
        "outputId": "8c0116e0-e264-4a8c-892f-664eb38deb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# X = X[:,:,:,np.newaxis] / 255\n",
        "# y = y[:,:,:,np.newaxis] / 255\n",
        "print(\"X shape : \", X.shape)\n",
        "print(\"y shape : \", y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape :  (5635, 128, 128, 1)\n",
            "y shape :  (5635, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT9XqEohb6CX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coefficent(img, mask):\n",
        "    smooth =1\n",
        "    img_points = K.flatten(img)\n",
        "    mask_points =K.flatten(mask)\n",
        "    intersection = K.sum(img_points*mask_points)\n",
        "    \n",
        "    coef = (2.*intersection + smooth) / (K.sum(img_points)+K.sum(mask_points) +smooth)\n",
        "    return coef\n",
        "\n",
        "def loss_dice(img,mask):\n",
        "    loss = - dice_coefficent(img,mask)\n",
        "    return loss\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st67qTkYb6Cb",
        "colab_type": "code",
        "outputId": "9e6f4b4e-b166-4cca-fbe9-71f3f811ec20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IMG_HEIGHT =128\n",
        "IMG_WIDTH = 128\n",
        "\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH,1))\n",
        "\n",
        "conv1 = Conv2D(32, (7, 7), activation='relu', padding='same')(inputs)\n",
        "conv1 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (7, 7), activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(64, (5, 5), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (7, 7), activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(128, (5, 5), activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(256, (7, 7), activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(256, (5, 5), activation='relu', padding='same')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = Conv2D(512, (7, 7), activation='relu', padding='same')(pool4)\n",
        "conv5 = Conv2D(512, (5, 5), activation='relu', padding='same')(conv5)\n",
        "\n",
        "up6 = concatenate([Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "conv6 = Conv2D(256, (7, 7), activation='relu', padding='same')(up6)\n",
        "conv6 = Conv2D(256, (5, 5), activation='relu', padding='same')(conv6)\n",
        "\n",
        "up7 = concatenate([Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "conv7 = Conv2D(128, (7, 7), activation='relu', padding='same')(up7)\n",
        "conv7 = Conv2D(128, (5,5), activation='relu', padding='same')(conv7)\n",
        "\n",
        "up8 = concatenate([Conv2DTranspose(64, (3,3), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "conv8 = Conv2D(64, (7,7), activation='relu', padding='same')(up8)\n",
        "conv8 = Conv2D(64, (5,5), activation='relu', padding='same')(conv8)\n",
        "\n",
        "up9 = concatenate([Conv2DTranspose(32, (3,3), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "conv9 = Conv2D(32, (7,7), activation='relu', padding='same')(up9)\n",
        "conv9 = Conv2D(32, (5,5), activation='relu', padding='same')(conv9)\n",
        "\n",
        "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "# model = Model(inputs=[inputs], outputs=[conv10])\n",
        "# model.compile(optimizer=Adam(lr = 1e-5), loss=loss_dice, metrics=[dice_coefficent])\n",
        "\n",
        "\n",
        "# def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
        "# inputs = Input((IMG_HEIGHT, IMG_WIDTH,1))\n",
        "# conv1 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "# conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "# # pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "# conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "# conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "# # pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "# conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "# conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "# # pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "# conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "# conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "# # drop4 = Dropout(0.5)(conv4)\n",
        "# pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "# conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "# conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "# drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "# up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "# merge6 = concatenate([drop4,up6], axis = 3)\n",
        "# conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "# conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "# up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "# merge7 = concatenate([conv3,up7], axis = 3)\n",
        "# conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "# conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "# up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "# merge8 = concatenate([conv2,up8], axis = 3)\n",
        "# conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "# conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "# up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "# merge9 = concatenate([conv1,up9], axis = 3)\n",
        "# conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "# conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "# conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9) # (merge9)\n",
        "# conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "model = Model(input = inputs, output = conv10)\n",
        "\n",
        "model.compile(optimizer = Adam(lr = 1e-5), loss = loss_dice, metrics=[dice_coefficent])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_-_o2wEb6Ce",
        "colab_type": "code",
        "outputId": "862a456f-1286-4a60-e5cc-dc031dc6e952",
        "colab": {}
      },
      "source": [
        "results = model.fit(X, y, validation_split=0.2,batch_size=4, epochs=20,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/20\n",
            "80/80 [==============================] - 17s 214ms/step - loss: -0.0240 - dice_coefficent: 0.0240 - val_loss: -0.0236 - val_dice_coefficent: 0.0236\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0241 - dice_coefficent: 0.0241 - val_loss: -0.0236 - val_dice_coefficent: 0.0236\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0242 - dice_coefficent: 0.0242 - val_loss: -0.0237 - val_dice_coefficent: 0.0237\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 17s 215ms/step - loss: -0.0243 - dice_coefficent: 0.0243 - val_loss: -0.0239 - val_dice_coefficent: 0.0239\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 17s 210ms/step - loss: -0.0245 - dice_coefficent: 0.0245 - val_loss: -0.0242 - val_dice_coefficent: 0.0242\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 17s 216ms/step - loss: -0.0249 - dice_coefficent: 0.0249 - val_loss: -0.0246 - val_dice_coefficent: 0.0246\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 17s 217ms/step - loss: -0.0254 - dice_coefficent: 0.0254 - val_loss: -0.0254 - val_dice_coefficent: 0.0254\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0264 - dice_coefficent: 0.0264 - val_loss: -0.0261 - val_dice_coefficent: 0.0261\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 17s 219ms/step - loss: -0.0269 - dice_coefficent: 0.0269 - val_loss: -0.0265 - val_dice_coefficent: 0.0265\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 17s 213ms/step - loss: -0.0273 - dice_coefficent: 0.0273 - val_loss: -0.0271 - val_dice_coefficent: 0.0271\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 17s 214ms/step - loss: -0.0281 - dice_coefficent: 0.0281 - val_loss: -0.0283 - val_dice_coefficent: 0.0283\n",
            "Epoch 12/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0297 - dice_coefficent: 0.0297 - val_loss: -0.0313 - val_dice_coefficent: 0.0313\n",
            "Epoch 13/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0332 - dice_coefficent: 0.0332 - val_loss: -0.0347 - val_dice_coefficent: 0.0347\n",
            "Epoch 14/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0358 - dice_coefficent: 0.0358 - val_loss: -0.0362 - val_dice_coefficent: 0.0362\n",
            "Epoch 15/20\n",
            "80/80 [==============================] - 17s 213ms/step - loss: -0.0381 - dice_coefficent: 0.0381 - val_loss: -0.0380 - val_dice_coefficent: 0.0380\n",
            "Epoch 16/20\n",
            "80/80 [==============================] - 17s 214ms/step - loss: -0.0388 - dice_coefficent: 0.0388 - val_loss: -0.0382 - val_dice_coefficent: 0.0382\n",
            "Epoch 17/20\n",
            "80/80 [==============================] - 17s 216ms/step - loss: -0.0390 - dice_coefficent: 0.0390 - val_loss: -0.0387 - val_dice_coefficent: 0.0387\n",
            "Epoch 18/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0429 - dice_coefficent: 0.0429 - val_loss: -0.0424 - val_dice_coefficent: 0.0424\n",
            "Epoch 19/20\n",
            "80/80 [==============================] - 17s 218ms/step - loss: -0.0551 - dice_coefficent: 0.0551 - val_loss: -0.0787 - val_dice_coefficent: 0.0787\n",
            "Epoch 20/20\n",
            "80/80 [==============================] - 17s 215ms/step - loss: -0.1030 - dice_coefficent: 0.1030 - val_loss: -0.1505 - val_dice_coefficent: 0.1505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFNpo40wfri0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PgZjt59b6Cj",
        "colab_type": "code",
        "outputId": "38fd24bd-fa51-4a24-c5e1-a68b13412213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def Generator(X_list, y_list, batch_size = 16):\n",
        "    while(True):\n",
        "      X = np.empty((batch_size, 128, 128,1), dtype = 'float32')\n",
        "      y = np.empty((batch_size, 128, 128,1), dtype = 'float32')\n",
        "      c = 0\n",
        "\n",
        "      for i in range(c,c+batch_size):\n",
        "          X[i - c] = X_list[i]\n",
        "          y[i - c] = y_list[i]\n",
        "\n",
        "      c += batch_size\n",
        "      if(c+batch_size >= len(X_list)):\n",
        "          c = 0\n",
        "      yield X, y   \n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "steps_per_epoch = int(len(X_train) / batch_size)\n",
        "validation_steps = int(len(X_val) / batch_size)\n",
        "print(validation_steps)\n",
        "train_gen = Generator(X_train, y_train, batch_size = batch_size)\n",
        "val_gen = Generator(X_val, y_val, batch_size = batch_size)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[conv10])\n",
        "model.compile(optimizer=Adam(lr = 1e-4), loss=loss_dice, metrics=[dice_coefficent])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBcW6r2QfIjk",
        "colab_type": "code",
        "outputId": "be73aff3-a796-4f01-a4e7-802fb339e878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=4, min_lr=1e-6)\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=steps_per_epoch, epochs = epochs,\n",
        "                             validation_data = val_gen, validation_steps = validation_steps,callbacks= [reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "281/281 [==============================] - 90s 319ms/step - loss: -0.1982 - dice_coefficent: 0.1982 - val_loss: -0.4891 - val_dice_coefficent: 0.4891\n",
            "Epoch 2/10\n",
            "281/281 [==============================] - 80s 286ms/step - loss: -0.7085 - dice_coefficent: 0.7085 - val_loss: -0.4956 - val_dice_coefficent: 0.4956\n",
            "Epoch 3/10\n",
            "281/281 [==============================] - 80s 285ms/step - loss: -0.9322 - dice_coefficent: 0.9322 - val_loss: -0.5675 - val_dice_coefficent: 0.5675\n",
            "Epoch 4/10\n",
            "281/281 [==============================] - 80s 285ms/step - loss: -0.9732 - dice_coefficent: 0.9732 - val_loss: -0.5626 - val_dice_coefficent: 0.5626\n",
            "Epoch 5/10\n",
            "281/281 [==============================] - 80s 284ms/step - loss: -0.9832 - dice_coefficent: 0.9832 - val_loss: -0.5700 - val_dice_coefficent: 0.5700\n",
            "Epoch 6/10\n",
            "281/281 [==============================] - 80s 284ms/step - loss: -0.9892 - dice_coefficent: 0.9892 - val_loss: -0.5875 - val_dice_coefficent: 0.5875\n",
            "Epoch 7/10\n",
            "281/281 [==============================] - 80s 284ms/step - loss: -0.9962 - dice_coefficent: 0.9962 - val_loss: -0.5865 - val_dice_coefficent: 0.5865\n",
            "Epoch 8/10\n",
            "281/281 [==============================] - 80s 284ms/step - loss: -0.9965 - dice_coefficent: 0.9965 - val_loss: -0.5861 - val_dice_coefficent: 0.5861\n",
            "Epoch 9/10\n",
            "281/281 [==============================] - 80s 284ms/step - loss: -0.9965 - dice_coefficent: 0.9965 - val_loss: -0.5862 - val_dice_coefficent: 0.5862\n",
            "Epoch 10/10\n",
            "281/281 [==============================] - 80s 284ms/step - loss: -0.9967 - dice_coefficent: 0.9967 - val_loss: -0.5864 - val_dice_coefficent: 0.5864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0wPbGu-b6Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_list = os.listdir(\"input/test/test\")\n",
        "# reg =re.compile(\"[0-9]+\")\n",
        "\n",
        "# temp1 = list(map(lambda x: reg.match(x).group(), test_list)) \n",
        "# temp1 = list(map(int, temp1))\n",
        "# test_list = [x for _,x in sorted(zip(temp1, test_list))]\n",
        "# X_test=[]\n",
        "# for i in range(len(test_list)):\n",
        "#     img = Image.open('input/test/test/'+test_list[i])\n",
        "#     img_resized = img.resize((128,128))\n",
        "#     X_test.append(np.array(img_resized))\n",
        "    \n",
        "# X_test= np.asarray(X_test)\n",
        "# X= X[:,:,:,np.newaxis]/255\n",
        "\n",
        "X_test = np.load('xtest.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAvWbcFib6Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred =model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9wK-Ddzb6Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_length_enc(label):\n",
        "    from itertools import chain\n",
        "    x = label.transpose().flatten()\n",
        "    y = np.where(x > 0)[0]\n",
        "    if len(y) < 10:  # consider as empty\n",
        "        return ''\n",
        "    z = np.where(np.diff(y) > 1)[0]\n",
        "    start = np.insert(y[z+1], 0, y[0])\n",
        "    end = np.append(y[z], y[-1])\n",
        "    length = end - start\n",
        "    res = [[s+1, l+1] for s, l in zip(list(start), list(length))]\n",
        "    res = list(chain.from_iterable(res))\n",
        "    return ' '.join([str(r) for r in res])\n",
        "\n",
        "\n",
        "rles = []\n",
        "for i in range(X_test.shape[0]):\n",
        "    img = y_pred[i, :, :, 0]\n",
        "    img = img > 0.5\n",
        "    img = resize(img, (420, 580), preserve_range=True)\n",
        "    rle = run_length_enc(img)\n",
        "    rles.append(rle)\n",
        "    if i % 100 == 0:\n",
        "        print('{}/{}'.format(i, X_test.shape[0]), end = \"\\r\")\n",
        "         \n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['pixels'] = rles\n",
        "sub.to_csv(\"submission4.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjI5kE8wb6Cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}